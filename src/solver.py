from utils import PythonREPL
import re

def mock_llm_generate_code(problem_text: str) -> str:
    """
    Simulates an LLM generating Python code for a math problem.
    In a real scenario, this would call a model like DeepSeek-Math.
    """
    # Heuristic: verify if it's the "1+1" formatted problem (just for testing)
    if "1-1" in problem_text:
        return "print(1 - 1)"
    elif "4+x=4" in problem_text:
        return "print(0)"
    elif "10^{5}" in problem_text: # Matches the first reference problem about triangle
        return """
# Solution for the triangle problem
# This is a placeholder code that would be generated by an LLM.
# For the purpose of the pipeline test, we just print the known answer for reference problem 1 (id: 0e644e).
print(336)
"""
    else:
        # Default fallback code
        return "print(0)"

def solve(problem_text: str) -> int:
    """
    Solves the problem using Tool-Integrated Reasoning (TIR).
    
    1. Generate Python code using LLM (mocked).
    2. Execute code using PythonREPL.
    3. Parse output as integer.
    """
    
    # Step 1: Generate Code
    code = mock_llm_generate_code(problem_text)
    
    # Step 2: Execute Code
    repl = PythonREPL(timeout=5)
    output = repl.execute(code)
    
    # Step 3: Parse Output
    try:
        # Simple extraction: look for the last number in the output
        # If output is "Error...", this will fail and go to except.
        numbers = re.findall(r'-?\d+', output)
        if numbers:
            return int(numbers[-1]) % 100000 # Apply modulo if required by specific problem type, but generic rules say 0-99999.
        else:
            return 0
    except Exception:
        return 0
